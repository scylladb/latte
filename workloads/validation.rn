// This rune script shows how we can do followig:
// - Validate the number of returned rows in 'SELECT' queries
// - Validate that the 'SELECT COUNT(...)' queries return integer equal to the expected rows number
// - Do above for partitions of any size using 'partitions preset' latte feature
// - Do above using prepared and non-prepared statements
//
// USAGE:
// 1) Create schema:
// $ latte schema workloads/validation.rn 172.17.0.2
//
// 2) Populate DB:
// $ latte run workloads/validation.rn -q \
//     -d 1000 -r 1000 -P row_count=1000 \
//     -P rows_per_partition=1 -P partition_sizes="\"50:4,50:6\"" \
//     -f insert -- 172.17.0.2
//
// 3) Do select queries with validation
//
// 3a) Get one row
// $ latte run workloads/validation.rn -q \
//     -d 1000 -r 1000 -P row_count=1000 \
//     -P rows_per_partition=1 -P partition_sizes="\"50:4,50:6\"" \
//     -f get -- 172.17.0.2
//
// 3b) Get many rows
// $ latte run workloads/validation.rn -q \
//     -d 1000 -r 1000 -P row_count=1000 \
//     -P rows_per_partition=1 -P partition_sizes="\"50:4,50:6\"" \
//     -f get_many -- 172.17.0.2
//
// 3c) Count
// $ latte run workloads/validation.rn -q \
//     -d 1000 -r 1000 -P row_count=1000 \
//     -P rows_per_partition=1 -P partition_sizes="\"50:4,50:6\"" \
//     -f count -- 172.17.0.2

use latte::*;

const ROW_COUNT = latte::param!("row_count", 1000000);
const OFFSET = latte::param!("offset", 0);
const REPLICATION_FACTOR = latte::param!("replication_factor", 3);
const ROWS_PER_PARTITION = latte::param!("rows_per_partition", 1);
// NOTE: 'partition_sizes' defines set of 'percent:multiplier' pairs to create multi-row partitions
// of different sizes. Example: '95:1,4:2,1:4'
const PARTITION_SIZES = latte::param!("partition_sizes", "100:1");

const USE_PREPARED_STATEMENTS = latte::param!("use_prepared_statements", true);

const KEYSPACE = "latte";
const TABLE = "validation";

const P_STMT = #{
    "INSERT": #{
        "NAME": "p_stmt_validation__insert",
        "CQL": `INSERT INTO ${KEYSPACE}.${TABLE}(pk, ck) VALUES (:pk, :ck)`,
    },
    "GET": #{
        "NAME": "p_stmt_validation__get",
        "CQL": `SELECT pk, ck FROM ${KEYSPACE}.${TABLE} WHERE pk = :pk LIMIT 1`,
    },
    "GET_MANY": #{
        "NAME": "p_stmt_validation__get_many",
        "CQL": `SELECT pk, ck FROM ${KEYSPACE}.${TABLE} WHERE pk = :pk LIMIT :max_limit`,
    },
    "COUNT": #{
        "NAME": "p_stmt_validation__count",
        "CQL": `SELECT COUNT(*) FROM ${KEYSPACE}.${TABLE} WHERE pk = :pk`,
    },
};

pub async fn schema(db) {
    db.execute(`CREATE KEYSPACE IF NOT EXISTS ${KEYSPACE} WITH REPLICATION = {
        'class': 'NetworkTopologyStrategy', 'replication_factor': ${REPLICATION_FACTOR} }`).await?;

    db.execute(`CREATE TABLE IF NOT EXISTS ${KEYSPACE}.${TABLE}(
        pk bigint,
        ck bigint,
        PRIMARY KEY (pk, ck)
    ) WITH CLUSTERING ORDER BY (ck ASC)`).await?;
}

pub async fn erase(db) {
    db.execute(`TRUNCATE TABLE ${KEYSPACE}.${TABLE}`).await?
}

pub async fn prepare(db) {
    db.init_partition_row_distribution_preset(
        "main", ROW_COUNT, ROWS_PER_PARTITION, PARTITION_SIZES,
    ).await?;
    db.prepare(P_STMT.INSERT.NAME, P_STMT.INSERT.CQL).await?;
    db.prepare(P_STMT.GET.NAME, P_STMT.GET.CQL).await?;
    db.prepare(P_STMT.GET_MANY.NAME, P_STMT.GET_MANY.CQL).await?;
    db.prepare(P_STMT.COUNT.NAME, P_STMT.COUNT.CQL).await?;
}

// User functions

pub async fn insert(db, i) { // validation is not applicable
    let idx = i % ROW_COUNT + OFFSET;
    let partition = db.get_partition_info("main", idx).await;
    partition.idx += OFFSET;
    let pk = hash(partition.idx);
    let ck = hash(idx);
    if USE_PREPARED_STATEMENTS {
        db.execute_prepared(P_STMT.INSERT.NAME, [pk, ck]).await?
    } else {
        db.execute(P_STMT.INSERT.CQL.replace(":pk", `${pk}`).replace(":ck", `${ck}`)).await?
    }
}

pub async fn get(db, i) { // make sure that we have only 1 row no matter how big partitions
    let idx = i % ROW_COUNT + OFFSET;
    let partition = db.get_partition_info("main", idx).await;
    partition.idx += OFFSET;
    let pk = hash(partition.idx);
    let custom_err = "custom very useful err msg for the 'get' function"; // optional
    let validation_args = [1, custom_err];
    if USE_PREPARED_STATEMENTS {
        db.execute_prepared_with_validation(P_STMT.GET.NAME, [pk], validation_args).await?
    } else {
        db.execute_with_validation(P_STMT.GET.CQL.replace(":pk", `${pk}`), validation_args).await?
    }
}

pub async fn get_many(db, i) { // make sure that we have rows num as expected
    let idx = i % ROW_COUNT + OFFSET;
    let partition = db.get_partition_info("main", idx).await;
    partition.idx += OFFSET;
    let pk = hash(partition.idx);
    let max_limit = partition.rows_num + 10; // make it be bigger than the expected value
    let custom_err = "custom very useful err msg for the 'get_many' function"; // optional
    let validation_args = [partition.rows_num, partition.rows_num, custom_err];
    if USE_PREPARED_STATEMENTS {
        db.execute_prepared_with_validation(P_STMT.GET_MANY.NAME, [pk, max_limit], validation_args).await?
    } else {
        let cql = P_STMT.GET_MANY.CQL.replace(":pk", `${pk}`).replace(":max_limit", `${max_limit}`);
        db.execute_with_validation(cql, validation_args).await?
    }
}

pub async fn count(db, i) { // checks that 'select count' integer result equals to the expected value
    let idx = i % ROW_COUNT + OFFSET;
    let partition = db.get_partition_info("main", idx).await;
    partition.idx += OFFSET;
    let pk = hash(partition.idx);
    let custom_err = "custom very useful err msg for 'count' function"; // optional
    let validation_args = [partition.rows_num, partition.rows_num, custom_err];
    if USE_PREPARED_STATEMENTS {
        db.execute_prepared_with_validation(P_STMT.COUNT.NAME, [pk], validation_args).await?
    } else {
        db.execute_with_validation(P_STMT.COUNT.CQL.replace(":pk", `${pk}`), validation_args).await?
    }
}
